# vllm engine args reference: https://docs.vllm.ai/en/latest/configuration/engine_args.html

models:
  - 
    name: "bark-small"
    model: "suno/bark-small"
    use_vllm: false
    usecase: "tts"
    plugin: "bark"
  # - 
  #   name: "orpheus"
  #   model: "unsloth/orpheus-3b-0.1-ft-unsloth-bnb-4bit"
  #   # use_vllm: false
  #   usecase: "tts"
  #   plugin: "orpheus"
  #   vllm_engine_kwargs:
  #     tensor_parallel_size: 1
  #     gpu_memory_utilization: 0.3
  #     trust_remote_code: 1
  #     max_model_len: 2048
  #     dtype: float16
  # -
  #   name: "Qwen2.5-VL-7B"
  #   model: "unsloth/Qwen2.5-VL-7B-Instruct-bnb-4bit"
  #   usecase: "generate"
  #   vllm_engine_kwargs:
  #     tensor_parallel_size: 1
  #     max_model_len: 32000
  #     gpu_memory_utilization: 0.8
  #     enable_log_requests: 1
  # - 
  #   name: "whisper"
  #   model: "openai/whisper-small"
  #   # use_vllm: false
  #   usecase: "transcription"
  #   vllm_engine_kwargs:
  #     tensor_parallel_size: 1
  #     gpu_memory_utilization: 0.20
  #     trust_remote_code: 1
  # - 
  #   name: "nomic-embed-text-v1.5"
  #   model: "nomic-ai/nomic-embed-text-v1.5"
  #   usecase: "embed"
  #   vllm_engine_kwargs:
  #     tensor_parallel_size: 1
  #     gpu_memory_utilization: 0.05
  #     trust_remote_code: 1
  
